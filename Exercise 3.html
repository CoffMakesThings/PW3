<!--
	Exercise 3 - Organize your code to easily implement a stream processing graph
-->

<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
		<style>
			body {
			margin: 0;
			padding: 0;
			width: 100%;
			height: 100%;
			
			margin: 0;
			overflow: hidden;
			background-color: #AAAAAA;
			background-attachment: fixed !important;
			}
		</style>
		<style>
			body {
				font-family: Monospace;
				margin: 0px;
				overflow: hidden;
			}
		</style>
	</head>
	<body>

	<script id="vertShader" type="shader">
		precision highp float;
	
		void main() {
			gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0 );
		}
	</script>

	<script id="fragShaderGaussian" type="shader">
		uniform sampler2D image;
		uniform int kernelSize;
		uniform float sigma;
	
		out vec4 out_FragColor;
	
		void main(void) {
			float pi = 3.14159265359;
			float eulers = 2.71828182846;

			float sampleX = gl_FragCoord.x;
			float sampleY = gl_FragCoord.y;
			
			int count = 0;
			vec4 value = vec4(0, 0, 0, 1);
			for (int x = -kernelSize; x < kernelSize + 1; x++) {
				for (int y = -kernelSize; y < kernelSize + 1; y++) {
					vec4 rawValue = texelFetch(image, ivec2(int(sampleX) + x, int(sampleY) + y), 0);
					float gauss = (1. / 2. * pi * pow(sigma, 2.)) * pow(eulers, -(pow(float(x), 2.) + pow(float(y), 2.)) / (2. * pow(sigma, 2.)));
					value += rawValue * gauss;
					count++;
				}
			}

			value = value / float(count);
			out_FragColor = value;
		}
	</script>

	<script id="fragShaderDenoising" type="shader">
		uniform sampler2D image;
		uniform int kernelOffset;
		uniform float coverage;
	
		out vec4 out_FragColor;

		void sort(inout float arr[amountOfKernels]) {
			// Insertion sort
			for (int x = 1; x < amountOfKernels; x++) {
				float currValue = arr[x];

				int y = x - 1;
				while (y >= 0 && currValue <= arr[y]) {
					arr[y + 1] = arr[y];
					y--;
				}

				arr[y + 1] = currValue;
			}
		}

		float getMean(float arr[amountOfKernels], int minRange, int maxRange) {
			float sum = 0.;

			for (int i = minRange; i <= maxRange; i++) {
				sum += arr[i];
			}

			int count = (maxRange - minRange) + 1;
			return sum / float(count);
		}

		void main(void) {
			float sampleX = gl_FragCoord.x;
			float sampleY = gl_FragCoord.y;

			float rs[amountOfKernels];
			float gs[amountOfKernels];
			float bs[amountOfKernels];

			int count = 0;

			for (int x = -kernelOffset; x < kernelOffset + 1; x++) {
				for (int y = -kernelOffset; y < kernelOffset + 1; y++) {
					vec3 textureValue = vec3(texelFetch(image, ivec2(int(sampleX) + x, int(sampleY) + y), 0).rgb);
					rs[count] = textureValue.r;
					gs[count] = textureValue.g;
					bs[count] = textureValue.b;
					count++;
				}
			}

			sort(rs);
			sort(gs);
			sort(bs);

			float middleIndex = float(amountOfKernels) / 2.;
			float indexRange = (float(amountOfKernels) * coverage) / 2.;
			int minRange = int(float(middleIndex) - indexRange);
			int maxRange = int(float(middleIndex) + indexRange);

			out_FragColor = vec4(getMean(rs, minRange, maxRange), getMean(gs, minRange, maxRange), getMean(bs, minRange, maxRange), 1.);
		}
	</script>
	
	<script id="fragShaderScaling" type="shader">
		uniform sampler2D image;
		uniform float scaleFactor;
		uniform bool bilinearFiltering;
		uniform bool frag;
	
		out vec4 out_FragColor;
	
		void main(void) {
			float sampleX = gl_FragCoord.x / scaleFactor;
			float sampleY = gl_FragCoord.y / scaleFactor;
			
			// Nearest neighbour
			vec4 textureValue = texelFetch(image, ivec2(int(sampleX), int(sampleY)), 0);

			if (bilinearFiltering) {
				// Bilinear Filtering
				ivec2 bottomLeftCoordinate = ivec2(floor(sampleX), floor(sampleY));
				ivec2 bottomRightCoordinate = ivec2(ceil(sampleX), floor(sampleY));
				ivec2 topLeftCoordinate = ivec2(floor(sampleX), ceil(sampleY));
				ivec2 topRightCoordinate = ivec2(ceil(sampleX), ceil(sampleY));

				vec4 bottomLeftValue = texelFetch( image, bottomLeftCoordinate, 0 );
				vec4 bottomRightValue = texelFetch( image, bottomRightCoordinate, 0 );
				vec4 topLeftValue = texelFetch( image, topLeftCoordinate, 0 );
				vec4 topRightValue = texelFetch( image, topRightCoordinate, 0 );

				vec4 topXAverage = topRightValue * (sampleX - floor(sampleX)) + topLeftValue * (ceil(sampleX) - sampleX);
				vec4 bottomXAverage = bottomRightValue * (sampleX - floor(sampleX)) + bottomLeftValue * (ceil(sampleX) - sampleX);
				vec4 average = topXAverage * (sampleY - floor(sampleY)) + bottomXAverage * (ceil(sampleY) - sampleY);

				textureValue = average;
			}
			if (frag) {
				// Show gradient of fragment coordinates
				float multiplier = gl_FragCoord.x / 3000. + gl_FragCoord.y / 1500.;
				textureValue = vec4(multiplier, multiplier, multiplier, 1);
			}
			out_FragColor = textureValue;
		}
	</script>

	<script id="fragShaderArithmetic" type="shader">
		uniform sampler2D image;
		uniform sampler2D image2;
		uniform float arithmeticScaling;
	
		out vec4 out_FragColor;
	
		void main(void) {
			float sampleX = gl_FragCoord.x;
			float sampleY = gl_FragCoord.y;
			
			vec4 textureValue = texelFetch(image, ivec2(int(sampleX), int(sampleY)), 0);
			vec4 textureValue2 = texelFetch(image2, ivec2(int(sampleX), int(sampleY)), 0);

			out_FragColor = (textureValue - textureValue2) * arithmeticScaling;
		}
	</script>
<script type="module">


import * as THREE from 'https://cdn.skypack.dev/three@0.136.0/build/three.module.js';
import { OrbitControls } from 'https://cdn.skypack.dev/three@0.136.0/examples/jsm/controls/OrbitControls.js';
import { GUI } from 'https://cdn.skypack.dev/three@0.136.0/examples/jsm/libs/lil-gui.module.min.js';
import { WEBGL } from 'https://cdn.skypack.dev/three@0.136.0/examples/jsm/WebGL.js';

var camera, controls, scene, renderer, container;
var context, canvas;
var plane1;
var plane2;
var loaderPromise, video, videoTexture;
var scalingHandler;
var arithmeticHandler;
var denoisingHandler;
var convolutionHandler;
var gui;

// Setup image processing
class ImageProcessingHandler {
	constructor( height, width, imageProcessingMaterial ) {
		this.height = height;
		this.width = width;

		this.scene = new THREE.Scene();
		this.orthoCamera = new THREE.OrthographicCamera(-1, 1, 1, -1, 1 / Math.pow( 2, 53 ), 1 );

		var options = {
			minFilter: THREE.NearestFilter,
			magFilter: THREE.NearestFilter,
			format: THREE.RGBAFormat,
			type: THREE.FloatType,
			canvas: canvas, 
			context: context
		};

		// this.rtt = new THREE.WebGLRenderTarget( width, height, options);
		this.rtt = new THREE.WebGLRenderTarget( width, height, options);

		var geom = new THREE.BufferGeometry();
		geom.addAttribute( 'position', new THREE.BufferAttribute( new Float32Array([-1, -1, 0, 1, -1, 0, 1, 1, 0, -1, -1, 0, 1, 1, 0, -1, 1, 0 ]), 3 ) );
		var mesh = new THREE.Mesh( geom, imageProcessingMaterial );
		this.scene.add( new THREE.Mesh( geom, imageProcessingMaterial ) );
	} 
}

function processImage ( imageProcessing, renderer )
{
	renderer.setRenderTarget( imageProcessing.rtt );
	renderer.render ( imageProcessing.scene, imageProcessing.orthoCamera ); 	
	renderer.setRenderTarget( null );
};

// Load sourceImage url param
const queryString = window.location.search;
const urlParams = new URLSearchParams(queryString);
var sourceImage = urlParams.get('sourceimage')
console.log("sourceImage is " + sourceImage);

if (sourceImage == null) {
	console.log("Defaulting sourceImage to image")
	sourceImage = 'image';
	console.log("sourceImage is " + sourceImage); 
}

// Load video from webcam
if (sourceImage == 'webcam') {
	loaderPromise = new Promise((resolve) => {
		if ( navigator.mediaDevices && navigator.mediaDevices.getUserMedia ) {
			const constraints = { video: { width: 1920, height: 1080, facingMode: 'user' } };
			resolve(navigator.mediaDevices.getUserMedia( constraints ));
		}
	}).then(stream => {
		return new Promise(resolve => {
			video = document.createElement('video');
			video.srcObject = stream;
			video.play();

			video.onloadeddata = () => { 
				videoTexture = new THREE.VideoTexture( video );
				videoTexture.minFilter = THREE.NearestFilter;
				videoTexture.magFilter = THREE.NearestFilter;
				videoTexture.generateMipmaps = false; 
				videoTexture.format = THREE.RGBFormat;

				resolve();
			}
		});
	});
}

// Load video from file
if (sourceImage == 'video') {
	video = document.createElement('video');
	video.src = 'video.mp4';
	video.load();
	video.muted = true;
	video.loop = true;

	loaderPromise = new Promise((resolve) => {
		video.onloadeddata = function () 
		{
			videoTexture = new THREE.VideoTexture( video );
			videoTexture.minFilter = THREE.NearestFilter;
			videoTexture.magFilter = THREE.NearestFilter;
			videoTexture.generateMipmaps = false; 
			videoTexture.format = THREE.RGBFormat;
			video.play();

			resolve();
		}
	});
}

// Load image
var imageTexture;

if (sourceImage == 'image') {
	loaderPromise = new Promise((resolve) => {
		imageTexture = new THREE.TextureLoader().load( 'grenouille.jpg', () => resolve() );
	});
}

loaderPromise.then(() => {
	init();
	animate();
});

function degToRad(degrees)
{
  var pi = Math.PI;
  return degrees * (pi/180);
}

function init () {
    if ( WEBGL.isWebGL2Available() === false ) {
		document.body.appendChild( WEBGL.getWebGL2ErrorMessage() );
	}	
    container = document.createElement( 'div' );
	document.body.appendChild( container );
	
    canvas = document.createElement( 'canvas' );
	context = canvas.getContext( 'webgl2' );
	document.body.appendChild( canvas );

	scene = new THREE.Scene(); 

	renderer = new THREE.WebGLRenderer( {  canvas: canvas, context: context});
	renderer.autoClear = false;
	renderer.setPixelRatio( window.devicePixelRatio );
	renderer.setSize( window.innerWidth, window.innerHeight );
	renderer.shadowMap.enabled = false;

	container.appendChild( renderer.domElement );

	camera = new THREE.PerspectiveCamera( 75, window.innerWidth / window.innerHeight, 0.001, 10 );
	camera.position.z = 0.7;
	controls = new OrbitControls( camera, renderer.domElement );
	controls.minDistance = 0.005;
	controls.maxDistance = 1.0;
	controls.enableRotate = true;
	controls.addEventListener( 'change', render );
	controls.update();
	
	var texture, aspect, width, height;

	switch(sourceImage) {
		case 'video':
		case 'webcam':
			texture = videoTexture;
			width = video.videoWidth;
			height = video.videoHeight;
			break;
		default:
			console.log(imageTexture);
			texture = imageTexture;
			width = imageTexture.image.width;
			height = imageTexture.image.height;
	}

	var aspect = height / width;
	var geometry = new THREE.PlaneGeometry( 1, aspect );

	var convolutionMaterial = new THREE.ShaderMaterial({
    	uniforms: {
			image: {type: 't', value: texture},
			scaleFactor: {type: 'f', value: 1},
			kernelSize: {type: 'i', value: 1},
			sigma: {type: 'f', value: 1}
    	},
    	vertexShader: document.getElementById('vertShader').text,
    	fragmentShader: document.getElementById('fragShaderGaussian').text,
        glslVersion: THREE.GLSL3
	});

	convolutionHandler = new ImageProcessingHandler ( height, width, convolutionMaterial );

	var denoisingMaterial = new THREE.ShaderMaterial({
    	uniforms: {
			image: {type: 't', value: texture},
			scaleFactor: {type: 'f', value: 1},
			kernelOffset: {type: 'i', value: 1},
			coverage: {type: 'f', value: 0.1}
    	},
		defines: {
			amountOfKernels: 9
		},
    	vertexShader: document.getElementById('vertShader').text,
    	fragmentShader: document.getElementById('fragShaderDenoising').text,
        glslVersion: THREE.GLSL3
	});

	denoisingHandler = new ImageProcessingHandler ( height, width, denoisingMaterial );

	var arithmeticMaterial = new THREE.ShaderMaterial({
    	uniforms: {
			image: {type: 't', value: convolutionHandler.rtt.texture},
			image2: {type: 't', value: denoisingHandler.rtt.texture},
			arithmeticScaling: {type: 'f', value: 200}
    	},
    	vertexShader: document.getElementById('vertShader').text,
    	fragmentShader: document.getElementById('fragShaderArithmetic').text,
        glslVersion: THREE.GLSL3
	});

	arithmeticHandler = new ImageProcessingHandler ( height, width, arithmeticMaterial );

	var scalingMaterial = new THREE.ShaderMaterial({
    	uniforms: {
			image: {type: 't', value: arithmeticHandler.rtt.texture },
        	scaleFactor: {type: 'f', value: 1},
			bilinearFiltering: {value: true}
    	},
    	vertexShader: document.getElementById('vertShader').text,
    	fragmentShader: document.getElementById('fragShaderScaling').text,
        glslVersion: THREE.GLSL3
	});

	scalingHandler = new ImageProcessingHandler ( height, width, scalingMaterial );

	// GUI

	const arithmeticOptions = {
      'Addition': 0,
      'Subtraction': 1,
      'Division': 2,
	  'Multiplication': 3
    }

	gui = new GUI();

	gui.add(scalingMaterial.uniforms.scaleFactor, 'value', 0, 8).name('Scale Factor').onChange(scaleFactor => {
		arithmeticMaterial.uniforms.scaleFactor = scalingMaterial.uniforms.scaleFactor;
		arithmeticHandler.rtt.setSize(scaleFactor * width, scaleFactor * height);
		scalingHandler.rtt.setSize(scaleFactor * width, scaleFactor * height);

		scene.remove( plane2 );
		var scaledGeometry = new THREE.PlaneGeometry( scaleFactor, scaleFactor * aspect );
		var material2 = new THREE.MeshBasicMaterial( { map: scalingHandler.rtt.texture, side: THREE.DoubleSide } );

		plane2 = new THREE.Mesh( scaledGeometry, material2 );
		scene.add(plane2);

		var distance = 1 / 2;
		plane1.position.x = -distance;
		plane2.position.x = distance * scaleFactor;
	});
	gui.add(scalingMaterial.uniforms.bilinearFiltering, 'value').name('Bilinear Filtering');
	gui.add(arithmeticMaterial.uniforms.arithmeticScaling, 'value', 1, 200).name('Arithmetic Scale Factor');

	var material1 = new THREE.MeshBasicMaterial( { map: texture, side: THREE.DoubleSide } );
	var material2 = new THREE.MeshBasicMaterial( { map: scalingHandler.rtt.texture, side : THREE.DoubleSide } );

	plane1 = new THREE.Mesh( geometry, material1 );
	plane1.receiveShadow = false;
	plane1.castShadow = false;
	scene.add( plane1 );

	plane2 = new THREE.Mesh( geometry, material2 );
	plane2.receiveShadow = false;
	plane2.castShadow = false;
	scene.add( plane2 );

	var distance = 1 / 2;
	plane1.position.x = -distance;
	plane2.position.x = distance;

	window.addEventListener( 'resize', onWindowResize, false );
}

function render () {
	renderer.clear();

	if (convolutionHandler) {
		processImage ( convolutionHandler, renderer );
	}

	if (denoisingHandler) {
		processImage ( denoisingHandler, renderer );
	}

	if (arithmeticHandler) {
		processImage ( arithmeticHandler, renderer );
	}

	if (scalingHandler) {
		processImage ( scalingHandler, renderer );
	}

	renderer.render( scene, camera );
}

function animate() {	
	requestAnimationFrame(animate);
	controls.update();
	render();
}

function onWindowResize () {
	camera.aspect = ( window.innerWidth / window.innerHeight);
	camera.updateProjectionMatrix();
	renderer.setSize( window.innerWidth, window.innerHeight );
	render();
}

</script>
</body>
</html>